{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WGll8U4XNX2g"
   },
   "source": [
    "## Work\n",
    "1. 請將 Epoch 加到 500 個，並觀察 learning curve 的走勢\n",
    "2. 請將 Optimizer 換成 SGD，並觀察 learning curve 的走勢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6443,
     "status": "ok",
     "timestamp": 1563807846933,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "s47I1hnyNaTl",
    "outputId": "3b275dae-5a40-40d5-8173-24bee04dfc86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.16.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2639,
     "status": "ok",
     "timestamp": 1563807868438,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "MgYjBgO3NX2i",
    "outputId": "43295f2a-a8fd-4d36-fc11-fbebc33691f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若有 GPU 且想開啟，可設為 \"0\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15198,
     "status": "ok",
     "timestamp": 1563807903254,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "Wb4royZKNX2l",
    "outputId": "ef9729f0-284c-4a59-d65b-cad8e56bbf2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bp8s9N0GNX2n"
   },
   "outputs": [],
   "source": [
    "# 將 X 與 Y 獨立放進變數\n",
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "# 資料前處理 - 標準化\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "# 將資料從圖形 (RGB) 轉為向量 (Single Vector)\n",
    "x_train = x_train.reshape((len(x_train), -1))\n",
    "x_test = x_test.reshape((len(x_test), -1))\n",
    "\n",
    "# 將目標轉為 one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1207,
     "status": "ok",
     "timestamp": 1563808749192,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "0YZoQymbNX2o",
    "outputId": "598ddf89-83ce-4257-9575-27292ebdb689"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0722 15:19:08.350315 140215727519616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0722 15:19:08.392905 140215727519616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0722 15:19:08.401334 140215727519616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def build_mlp():\n",
    "    \"\"\"Code Here\n",
    "    建立你的神經網路\n",
    "    \"\"\"\n",
    "    input_layer = keras.layers.Input([x_train.shape[-1]])\n",
    "    l1 = keras.layers.Dense(units=512, activation=\"relu\")(input_layer)\n",
    "    l2 = keras.layers.Dense(units=256, activation=\"relu\")(l1)\n",
    "    l3 = keras.layers.Dense(units=128, activation=\"relu\")(l2)\n",
    "    out = keras.layers.Dense(units=10, activation=\"softmax\")(l3)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "\n",
    "    return model\n",
    "model = build_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1033,
     "status": "ok",
     "timestamp": 1563808765024,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "FriO--CwNX2q",
    "outputId": "c19a5fb5-8ba9-4aa2-b139-d267c1b495c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 15:19:24.449088 140215727519616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0722 15:19:24.462538 140215727519616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compile 模型\n",
    "\"\"\"\n",
    "model = build_mlp()\n",
    "\n",
    "# 用 Keras 內建方法檢視模型各層參數量\n",
    "model.summary()\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1387723,
     "status": "ok",
     "timestamp": 1563810238900,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "MVBarEY3NX2s",
    "outputId": "6e6e9a5b-97d1-4bba-e8e5-f3f48c240a8f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0722 15:20:51.679139 140215727519616 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0722 15:20:51.749564 140215727519616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 2.2611 - acc: 0.1577 - val_loss: 2.2164 - val_acc: 0.1911\n",
      "Epoch 2/500\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 2.1848 - acc: 0.2113 - val_loss: 2.1565 - val_acc: 0.2257\n",
      "Epoch 3/500\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 2.1314 - acc: 0.2362 - val_loss: 2.1094 - val_acc: 0.2415\n",
      "Epoch 4/500\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 2.0883 - acc: 0.2516 - val_loss: 2.0710 - val_acc: 0.2555\n",
      "Epoch 5/500\n",
      "50000/50000 [==============================] - 2s 49us/step - loss: 2.0528 - acc: 0.2642 - val_loss: 2.0389 - val_acc: 0.2682\n",
      "Epoch 6/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 2.0229 - acc: 0.2768 - val_loss: 2.0104 - val_acc: 0.2824\n",
      "Epoch 7/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.9969 - acc: 0.2891 - val_loss: 1.9869 - val_acc: 0.2939\n",
      "Epoch 8/500\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.9746 - acc: 0.2991 - val_loss: 1.9671 - val_acc: 0.3070\n",
      "Epoch 9/500\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.9552 - acc: 0.3081 - val_loss: 1.9476 - val_acc: 0.3158\n",
      "Epoch 10/500\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.9376 - acc: 0.3161 - val_loss: 1.9316 - val_acc: 0.3195\n",
      "Epoch 11/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.9216 - acc: 0.3250 - val_loss: 1.9161 - val_acc: 0.3271\n",
      "Epoch 12/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.9070 - acc: 0.3327 - val_loss: 1.9022 - val_acc: 0.3334\n",
      "Epoch 13/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8936 - acc: 0.3385 - val_loss: 1.8897 - val_acc: 0.3401\n",
      "Epoch 14/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8816 - acc: 0.3424 - val_loss: 1.8779 - val_acc: 0.3414\n",
      "Epoch 15/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8705 - acc: 0.3469 - val_loss: 1.8676 - val_acc: 0.3471\n",
      "Epoch 16/500\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.8602 - acc: 0.3522 - val_loss: 1.8582 - val_acc: 0.3519\n",
      "Epoch 17/500\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.8505 - acc: 0.3558 - val_loss: 1.8486 - val_acc: 0.3535\n",
      "Epoch 18/500\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.8414 - acc: 0.3582 - val_loss: 1.8395 - val_acc: 0.3587\n",
      "Epoch 19/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8329 - acc: 0.3614 - val_loss: 1.8318 - val_acc: 0.3608\n",
      "Epoch 20/500\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.8248 - acc: 0.3633 - val_loss: 1.8239 - val_acc: 0.3596\n",
      "Epoch 21/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8170 - acc: 0.3667 - val_loss: 1.8153 - val_acc: 0.3648\n",
      "Epoch 22/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8096 - acc: 0.3698 - val_loss: 1.8082 - val_acc: 0.3688\n",
      "Epoch 23/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.8030 - acc: 0.3711 - val_loss: 1.8021 - val_acc: 0.3726\n",
      "Epoch 24/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7963 - acc: 0.3743 - val_loss: 1.7949 - val_acc: 0.3738\n",
      "Epoch 25/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7898 - acc: 0.3760 - val_loss: 1.7893 - val_acc: 0.3794\n",
      "Epoch 26/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7835 - acc: 0.3781 - val_loss: 1.7838 - val_acc: 0.3791\n",
      "Epoch 27/500\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.7781 - acc: 0.3789 - val_loss: 1.7782 - val_acc: 0.3821\n",
      "Epoch 28/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7727 - acc: 0.3824 - val_loss: 1.7721 - val_acc: 0.3789\n",
      "Epoch 29/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7671 - acc: 0.3838 - val_loss: 1.7674 - val_acc: 0.3814\n",
      "Epoch 30/500\n",
      "50000/50000 [==============================] - 2s 50us/step - loss: 1.7620 - acc: 0.3856 - val_loss: 1.7612 - val_acc: 0.3857\n",
      "Epoch 31/500\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7570 - acc: 0.3879 - val_loss: 1.7574 - val_acc: 0.3891\n",
      "Epoch 32/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.7523 - acc: 0.3894 - val_loss: 1.7520 - val_acc: 0.3897\n",
      "Epoch 33/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.7481 - acc: 0.3908 - val_loss: 1.7476 - val_acc: 0.3919\n",
      "Epoch 34/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.7432 - acc: 0.3928 - val_loss: 1.7439 - val_acc: 0.3935\n",
      "Epoch 35/500\n",
      "50000/50000 [==============================] - 3s 52us/step - loss: 1.7390 - acc: 0.3932 - val_loss: 1.7384 - val_acc: 0.3963\n",
      "Epoch 36/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7348 - acc: 0.3944 - val_loss: 1.7354 - val_acc: 0.3951\n",
      "Epoch 37/500\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.7305 - acc: 0.3965 - val_loss: 1.7331 - val_acc: 0.3935\n",
      "Epoch 38/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7265 - acc: 0.3980 - val_loss: 1.7270 - val_acc: 0.3986\n",
      "Epoch 39/500\n",
      "50000/50000 [==============================] - 3s 50us/step - loss: 1.7225 - acc: 0.3999 - val_loss: 1.7244 - val_acc: 0.3978\n",
      "Epoch 40/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7186 - acc: 0.4017 - val_loss: 1.7200 - val_acc: 0.4014\n",
      "Epoch 41/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7148 - acc: 0.4032 - val_loss: 1.7163 - val_acc: 0.4031\n",
      "Epoch 42/500\n",
      "50000/50000 [==============================] - 3s 51us/step - loss: 1.7111 - acc: 0.4036 - val_loss: 1.7129 - val_acc: 0.4065\n",
      "Epoch 43/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.7075 - acc: 0.4056 - val_loss: 1.7094 - val_acc: 0.4040\n",
      "Epoch 44/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.7039 - acc: 0.4070 - val_loss: 1.7047 - val_acc: 0.4081\n",
      "Epoch 45/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.7006 - acc: 0.4078 - val_loss: 1.7038 - val_acc: 0.4075\n",
      "Epoch 46/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6970 - acc: 0.4093 - val_loss: 1.6993 - val_acc: 0.4105\n",
      "Epoch 47/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6934 - acc: 0.4103 - val_loss: 1.6974 - val_acc: 0.4110\n",
      "Epoch 48/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6903 - acc: 0.4115 - val_loss: 1.6926 - val_acc: 0.4112\n",
      "Epoch 49/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6867 - acc: 0.4119 - val_loss: 1.6924 - val_acc: 0.4088\n",
      "Epoch 50/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.6834 - acc: 0.4139 - val_loss: 1.6876 - val_acc: 0.4142\n",
      "Epoch 51/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6803 - acc: 0.4148 - val_loss: 1.6835 - val_acc: 0.4127\n",
      "Epoch 52/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6770 - acc: 0.4166 - val_loss: 1.6837 - val_acc: 0.4166\n",
      "Epoch 53/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.6739 - acc: 0.4179 - val_loss: 1.6770 - val_acc: 0.4157\n",
      "Epoch 54/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.6710 - acc: 0.4187 - val_loss: 1.6749 - val_acc: 0.4155\n",
      "Epoch 55/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.6677 - acc: 0.4205 - val_loss: 1.6725 - val_acc: 0.4160\n",
      "Epoch 56/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6647 - acc: 0.4206 - val_loss: 1.6681 - val_acc: 0.4210\n",
      "Epoch 57/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6615 - acc: 0.4215 - val_loss: 1.6665 - val_acc: 0.4175\n",
      "Epoch 58/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6586 - acc: 0.4240 - val_loss: 1.6618 - val_acc: 0.4231\n",
      "Epoch 59/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.6555 - acc: 0.4243 - val_loss: 1.6608 - val_acc: 0.4229\n",
      "Epoch 60/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6527 - acc: 0.4250 - val_loss: 1.6613 - val_acc: 0.4222\n",
      "Epoch 61/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6498 - acc: 0.4274 - val_loss: 1.6544 - val_acc: 0.4219\n",
      "Epoch 62/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6465 - acc: 0.4284 - val_loss: 1.6524 - val_acc: 0.4257\n",
      "Epoch 63/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.6438 - acc: 0.4290 - val_loss: 1.6499 - val_acc: 0.4245\n",
      "Epoch 64/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6413 - acc: 0.4300 - val_loss: 1.6499 - val_acc: 0.4245\n",
      "Epoch 65/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6383 - acc: 0.4322 - val_loss: 1.6472 - val_acc: 0.4268\n",
      "Epoch 66/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6357 - acc: 0.4321 - val_loss: 1.6404 - val_acc: 0.4277\n",
      "Epoch 67/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6327 - acc: 0.4335 - val_loss: 1.6430 - val_acc: 0.4246\n",
      "Epoch 68/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.6303 - acc: 0.4334 - val_loss: 1.6377 - val_acc: 0.4290\n",
      "Epoch 69/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6272 - acc: 0.4352 - val_loss: 1.6346 - val_acc: 0.4256\n",
      "Epoch 70/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6246 - acc: 0.4364 - val_loss: 1.6330 - val_acc: 0.4308\n",
      "Epoch 71/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.6220 - acc: 0.4367 - val_loss: 1.6308 - val_acc: 0.4300\n",
      "Epoch 72/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6195 - acc: 0.4381 - val_loss: 1.6278 - val_acc: 0.4329\n",
      "Epoch 73/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6165 - acc: 0.4399 - val_loss: 1.6235 - val_acc: 0.4313\n",
      "Epoch 74/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.6143 - acc: 0.4395 - val_loss: 1.6247 - val_acc: 0.4312\n",
      "Epoch 75/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6113 - acc: 0.4400 - val_loss: 1.6197 - val_acc: 0.4365\n",
      "Epoch 76/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6090 - acc: 0.4422 - val_loss: 1.6222 - val_acc: 0.4288\n",
      "Epoch 77/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.6065 - acc: 0.4434 - val_loss: 1.6186 - val_acc: 0.4356\n",
      "Epoch 78/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6037 - acc: 0.4438 - val_loss: 1.6142 - val_acc: 0.4392\n",
      "Epoch 79/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.6015 - acc: 0.4434 - val_loss: 1.6121 - val_acc: 0.4382\n",
      "Epoch 80/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5990 - acc: 0.4456 - val_loss: 1.6102 - val_acc: 0.4346\n",
      "Epoch 81/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5963 - acc: 0.4450 - val_loss: 1.6070 - val_acc: 0.4404\n",
      "Epoch 82/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5939 - acc: 0.4469 - val_loss: 1.6052 - val_acc: 0.4385\n",
      "Epoch 83/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5916 - acc: 0.4469 - val_loss: 1.6038 - val_acc: 0.4401\n",
      "Epoch 84/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.5892 - acc: 0.4481 - val_loss: 1.6019 - val_acc: 0.4388\n",
      "Epoch 85/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5867 - acc: 0.4493 - val_loss: 1.5999 - val_acc: 0.4444\n",
      "Epoch 86/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5843 - acc: 0.4499 - val_loss: 1.5960 - val_acc: 0.4422\n",
      "Epoch 87/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.5818 - acc: 0.4505 - val_loss: 1.6005 - val_acc: 0.4379\n",
      "Epoch 88/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5798 - acc: 0.4507 - val_loss: 1.5929 - val_acc: 0.4439\n",
      "Epoch 89/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5772 - acc: 0.4528 - val_loss: 1.5894 - val_acc: 0.4460\n",
      "Epoch 90/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5753 - acc: 0.4524 - val_loss: 1.5883 - val_acc: 0.4439\n",
      "Epoch 91/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5726 - acc: 0.4526 - val_loss: 1.5877 - val_acc: 0.4447\n",
      "Epoch 92/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5704 - acc: 0.4548 - val_loss: 1.5869 - val_acc: 0.4446\n",
      "Epoch 93/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.5682 - acc: 0.4561 - val_loss: 1.5847 - val_acc: 0.4467\n",
      "Epoch 94/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5659 - acc: 0.4562 - val_loss: 1.5812 - val_acc: 0.4457\n",
      "Epoch 95/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5636 - acc: 0.4557 - val_loss: 1.5811 - val_acc: 0.4488\n",
      "Epoch 96/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5615 - acc: 0.4585 - val_loss: 1.5754 - val_acc: 0.4482\n",
      "Epoch 97/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5591 - acc: 0.4589 - val_loss: 1.5748 - val_acc: 0.4495\n",
      "Epoch 98/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5571 - acc: 0.4589 - val_loss: 1.5727 - val_acc: 0.4506\n",
      "Epoch 99/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5547 - acc: 0.4594 - val_loss: 1.5719 - val_acc: 0.4507\n",
      "Epoch 100/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5529 - acc: 0.4612 - val_loss: 1.5713 - val_acc: 0.4474\n",
      "Epoch 101/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5509 - acc: 0.4620 - val_loss: 1.5685 - val_acc: 0.4519\n",
      "Epoch 102/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5485 - acc: 0.4625 - val_loss: 1.5672 - val_acc: 0.4476\n",
      "Epoch 103/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.5461 - acc: 0.4630 - val_loss: 1.5666 - val_acc: 0.4486\n",
      "Epoch 104/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5444 - acc: 0.4639 - val_loss: 1.5619 - val_acc: 0.4541\n",
      "Epoch 105/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5424 - acc: 0.4634 - val_loss: 1.5613 - val_acc: 0.4529\n",
      "Epoch 106/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5400 - acc: 0.4651 - val_loss: 1.5644 - val_acc: 0.4536\n",
      "Epoch 107/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5385 - acc: 0.4647 - val_loss: 1.5568 - val_acc: 0.4526\n",
      "Epoch 108/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5362 - acc: 0.4672 - val_loss: 1.5565 - val_acc: 0.4543\n",
      "Epoch 109/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5344 - acc: 0.4665 - val_loss: 1.5551 - val_acc: 0.4542\n",
      "Epoch 110/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5326 - acc: 0.4667 - val_loss: 1.5560 - val_acc: 0.4529\n",
      "Epoch 111/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5306 - acc: 0.4678 - val_loss: 1.5519 - val_acc: 0.4545\n",
      "Epoch 112/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5284 - acc: 0.4679 - val_loss: 1.5506 - val_acc: 0.4566\n",
      "Epoch 113/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5262 - acc: 0.4689 - val_loss: 1.5499 - val_acc: 0.4585\n",
      "Epoch 114/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5243 - acc: 0.4708 - val_loss: 1.5477 - val_acc: 0.4583\n",
      "Epoch 115/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5226 - acc: 0.4699 - val_loss: 1.5488 - val_acc: 0.4559\n",
      "Epoch 116/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5207 - acc: 0.4712 - val_loss: 1.5539 - val_acc: 0.4563\n",
      "Epoch 117/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5188 - acc: 0.4709 - val_loss: 1.5468 - val_acc: 0.4575\n",
      "Epoch 118/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5170 - acc: 0.4717 - val_loss: 1.5476 - val_acc: 0.4551\n",
      "Epoch 119/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5150 - acc: 0.4731 - val_loss: 1.5398 - val_acc: 0.4599\n",
      "Epoch 120/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5132 - acc: 0.4738 - val_loss: 1.5393 - val_acc: 0.4570\n",
      "Epoch 121/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.5113 - acc: 0.4738 - val_loss: 1.5361 - val_acc: 0.4624\n",
      "Epoch 122/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5096 - acc: 0.4745 - val_loss: 1.5372 - val_acc: 0.4591\n",
      "Epoch 123/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5077 - acc: 0.4740 - val_loss: 1.5363 - val_acc: 0.4609\n",
      "Epoch 124/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5057 - acc: 0.4755 - val_loss: 1.5331 - val_acc: 0.4611\n",
      "Epoch 125/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5041 - acc: 0.4754 - val_loss: 1.5320 - val_acc: 0.4606\n",
      "Epoch 126/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.5023 - acc: 0.4772 - val_loss: 1.5303 - val_acc: 0.4590\n",
      "Epoch 127/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.5004 - acc: 0.4771 - val_loss: 1.5272 - val_acc: 0.4641\n",
      "Epoch 128/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4987 - acc: 0.4772 - val_loss: 1.5293 - val_acc: 0.4640\n",
      "Epoch 129/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4970 - acc: 0.4783 - val_loss: 1.5286 - val_acc: 0.4625\n",
      "Epoch 130/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4951 - acc: 0.4789 - val_loss: 1.5224 - val_acc: 0.4643\n",
      "Epoch 131/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4933 - acc: 0.4800 - val_loss: 1.5238 - val_acc: 0.4632\n",
      "Epoch 132/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4916 - acc: 0.4802 - val_loss: 1.5209 - val_acc: 0.4638\n",
      "Epoch 133/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4896 - acc: 0.4800 - val_loss: 1.5195 - val_acc: 0.4666\n",
      "Epoch 134/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4881 - acc: 0.4811 - val_loss: 1.5179 - val_acc: 0.4681\n",
      "Epoch 135/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4864 - acc: 0.4817 - val_loss: 1.5191 - val_acc: 0.4674\n",
      "Epoch 136/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4843 - acc: 0.4827 - val_loss: 1.5162 - val_acc: 0.4669\n",
      "Epoch 137/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4829 - acc: 0.4826 - val_loss: 1.5160 - val_acc: 0.4662\n",
      "Epoch 138/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4812 - acc: 0.4834 - val_loss: 1.5204 - val_acc: 0.4615\n",
      "Epoch 139/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4799 - acc: 0.4843 - val_loss: 1.5147 - val_acc: 0.4687\n",
      "Epoch 140/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4775 - acc: 0.4855 - val_loss: 1.5117 - val_acc: 0.4681\n",
      "Epoch 141/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4760 - acc: 0.4859 - val_loss: 1.5087 - val_acc: 0.4705\n",
      "Epoch 142/500\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 1.4744 - acc: 0.4863 - val_loss: 1.5091 - val_acc: 0.4672\n",
      "Epoch 143/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4727 - acc: 0.4878 - val_loss: 1.5057 - val_acc: 0.4711\n",
      "Epoch 144/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.4707 - acc: 0.4877 - val_loss: 1.5041 - val_acc: 0.4707\n",
      "Epoch 145/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4694 - acc: 0.4879 - val_loss: 1.5033 - val_acc: 0.4704\n",
      "Epoch 146/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4675 - acc: 0.4884 - val_loss: 1.5034 - val_acc: 0.4741\n",
      "Epoch 147/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4662 - acc: 0.4891 - val_loss: 1.5104 - val_acc: 0.4665\n",
      "Epoch 148/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4640 - acc: 0.4897 - val_loss: 1.4993 - val_acc: 0.4731\n",
      "Epoch 149/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4626 - acc: 0.4902 - val_loss: 1.5021 - val_acc: 0.4687\n",
      "Epoch 150/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4609 - acc: 0.4917 - val_loss: 1.5010 - val_acc: 0.4711\n",
      "Epoch 151/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4593 - acc: 0.4918 - val_loss: 1.4998 - val_acc: 0.4696\n",
      "Epoch 152/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4576 - acc: 0.4921 - val_loss: 1.4954 - val_acc: 0.4744\n",
      "Epoch 153/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4561 - acc: 0.4929 - val_loss: 1.4931 - val_acc: 0.4736\n",
      "Epoch 154/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4543 - acc: 0.4938 - val_loss: 1.4952 - val_acc: 0.4696\n",
      "Epoch 155/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4530 - acc: 0.4939 - val_loss: 1.4943 - val_acc: 0.4773\n",
      "Epoch 156/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4513 - acc: 0.4951 - val_loss: 1.4917 - val_acc: 0.4727\n",
      "Epoch 157/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4497 - acc: 0.4952 - val_loss: 1.4951 - val_acc: 0.4725\n",
      "Epoch 158/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4481 - acc: 0.4951 - val_loss: 1.4917 - val_acc: 0.4727\n",
      "Epoch 159/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4461 - acc: 0.4956 - val_loss: 1.4934 - val_acc: 0.4710\n",
      "Epoch 160/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.4446 - acc: 0.4962 - val_loss: 1.4854 - val_acc: 0.4753\n",
      "Epoch 161/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4431 - acc: 0.4972 - val_loss: 1.4857 - val_acc: 0.4739\n",
      "Epoch 162/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4416 - acc: 0.4978 - val_loss: 1.4882 - val_acc: 0.4725\n",
      "Epoch 163/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4400 - acc: 0.4978 - val_loss: 1.4864 - val_acc: 0.4731\n",
      "Epoch 164/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4385 - acc: 0.4987 - val_loss: 1.4825 - val_acc: 0.4766\n",
      "Epoch 165/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4363 - acc: 0.5004 - val_loss: 1.4812 - val_acc: 0.4781\n",
      "Epoch 166/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4351 - acc: 0.5004 - val_loss: 1.4898 - val_acc: 0.4765\n",
      "Epoch 167/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4341 - acc: 0.5002 - val_loss: 1.4773 - val_acc: 0.4815\n",
      "Epoch 168/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.4321 - acc: 0.5013 - val_loss: 1.4811 - val_acc: 0.4753\n",
      "Epoch 169/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4307 - acc: 0.5011 - val_loss: 1.4819 - val_acc: 0.4757\n",
      "Epoch 170/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4289 - acc: 0.5028 - val_loss: 1.4779 - val_acc: 0.4789\n",
      "Epoch 171/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4277 - acc: 0.5035 - val_loss: 1.4741 - val_acc: 0.4821\n",
      "Epoch 172/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4258 - acc: 0.5028 - val_loss: 1.4740 - val_acc: 0.4801\n",
      "Epoch 173/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4243 - acc: 0.5050 - val_loss: 1.4719 - val_acc: 0.4825\n",
      "Epoch 174/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.4225 - acc: 0.5038 - val_loss: 1.4760 - val_acc: 0.4797\n",
      "Epoch 175/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4209 - acc: 0.5053 - val_loss: 1.4693 - val_acc: 0.4816\n",
      "Epoch 176/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4192 - acc: 0.5052 - val_loss: 1.4678 - val_acc: 0.4823\n",
      "Epoch 177/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.4182 - acc: 0.5067 - val_loss: 1.4768 - val_acc: 0.4773\n",
      "Epoch 178/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4166 - acc: 0.5063 - val_loss: 1.4664 - val_acc: 0.4794\n",
      "Epoch 179/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4150 - acc: 0.5076 - val_loss: 1.4714 - val_acc: 0.4799\n",
      "Epoch 180/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4133 - acc: 0.5071 - val_loss: 1.4677 - val_acc: 0.4815\n",
      "Epoch 181/500\n",
      "50000/50000 [==============================] - 3s 60us/step - loss: 1.4122 - acc: 0.5086 - val_loss: 1.4624 - val_acc: 0.4836\n",
      "Epoch 182/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.4104 - acc: 0.5080 - val_loss: 1.4736 - val_acc: 0.4796\n",
      "Epoch 183/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4088 - acc: 0.5087 - val_loss: 1.4686 - val_acc: 0.4788\n",
      "Epoch 184/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.4073 - acc: 0.5096 - val_loss: 1.4594 - val_acc: 0.4865\n",
      "Epoch 185/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4056 - acc: 0.5102 - val_loss: 1.4656 - val_acc: 0.4848\n",
      "Epoch 186/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.4045 - acc: 0.5116 - val_loss: 1.4642 - val_acc: 0.4793\n",
      "Epoch 187/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4032 - acc: 0.5115 - val_loss: 1.4611 - val_acc: 0.4838\n",
      "Epoch 188/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.4013 - acc: 0.5123 - val_loss: 1.4609 - val_acc: 0.4860\n",
      "Epoch 189/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.3998 - acc: 0.5126 - val_loss: 1.4842 - val_acc: 0.4757\n",
      "Epoch 190/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.3983 - acc: 0.5134 - val_loss: 1.4559 - val_acc: 0.4830\n",
      "Epoch 191/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.3969 - acc: 0.5130 - val_loss: 1.4589 - val_acc: 0.4837\n",
      "Epoch 192/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.3953 - acc: 0.5146 - val_loss: 1.4586 - val_acc: 0.4851\n",
      "Epoch 193/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.3935 - acc: 0.5147 - val_loss: 1.4538 - val_acc: 0.4878\n",
      "Epoch 194/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.3922 - acc: 0.5145 - val_loss: 1.4507 - val_acc: 0.4841\n",
      "Epoch 195/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.3907 - acc: 0.5141 - val_loss: 1.4564 - val_acc: 0.4857\n",
      "Epoch 196/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.3896 - acc: 0.5160 - val_loss: 1.4522 - val_acc: 0.4868\n",
      "Epoch 197/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.3880 - acc: 0.5156 - val_loss: 1.4474 - val_acc: 0.4896\n",
      "Epoch 198/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.3865 - acc: 0.5178 - val_loss: 1.4505 - val_acc: 0.4888\n",
      "Epoch 199/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.3846 - acc: 0.5169 - val_loss: 1.4472 - val_acc: 0.4884\n",
      "Epoch 200/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.3834 - acc: 0.5179 - val_loss: 1.4521 - val_acc: 0.4848\n",
      "Epoch 201/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3819 - acc: 0.5179 - val_loss: 1.4544 - val_acc: 0.4886\n",
      "Epoch 202/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3804 - acc: 0.5182 - val_loss: 1.4546 - val_acc: 0.4869\n",
      "Epoch 203/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.3790 - acc: 0.5191 - val_loss: 1.4474 - val_acc: 0.4891\n",
      "Epoch 204/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.3774 - acc: 0.5209 - val_loss: 1.4479 - val_acc: 0.4892\n",
      "Epoch 205/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3762 - acc: 0.5199 - val_loss: 1.4450 - val_acc: 0.4872\n",
      "Epoch 206/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3744 - acc: 0.5210 - val_loss: 1.4409 - val_acc: 0.4875\n",
      "Epoch 207/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3732 - acc: 0.5214 - val_loss: 1.4565 - val_acc: 0.4835\n",
      "Epoch 208/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.3718 - acc: 0.5215 - val_loss: 1.4399 - val_acc: 0.4886\n",
      "Epoch 209/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3702 - acc: 0.5221 - val_loss: 1.4435 - val_acc: 0.4916\n",
      "Epoch 210/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3690 - acc: 0.5222 - val_loss: 1.4356 - val_acc: 0.4910\n",
      "Epoch 211/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.3676 - acc: 0.5236 - val_loss: 1.4414 - val_acc: 0.4942\n",
      "Epoch 212/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3660 - acc: 0.5251 - val_loss: 1.4371 - val_acc: 0.4924\n",
      "Epoch 213/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3648 - acc: 0.5238 - val_loss: 1.4364 - val_acc: 0.4877\n",
      "Epoch 214/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3627 - acc: 0.5238 - val_loss: 1.4314 - val_acc: 0.4951\n",
      "Epoch 215/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3621 - acc: 0.5253 - val_loss: 1.4324 - val_acc: 0.4925\n",
      "Epoch 216/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.3608 - acc: 0.5258 - val_loss: 1.4352 - val_acc: 0.4921\n",
      "Epoch 217/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3595 - acc: 0.5261 - val_loss: 1.4344 - val_acc: 0.4920\n",
      "Epoch 218/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3574 - acc: 0.5262 - val_loss: 1.4297 - val_acc: 0.4950\n",
      "Epoch 219/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3557 - acc: 0.5273 - val_loss: 1.4329 - val_acc: 0.4922\n",
      "Epoch 220/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3548 - acc: 0.5268 - val_loss: 1.4397 - val_acc: 0.4911\n",
      "Epoch 221/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3534 - acc: 0.5282 - val_loss: 1.4298 - val_acc: 0.4907\n",
      "Epoch 222/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3522 - acc: 0.5283 - val_loss: 1.4336 - val_acc: 0.4904\n",
      "Epoch 223/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3506 - acc: 0.5289 - val_loss: 1.4255 - val_acc: 0.4960\n",
      "Epoch 224/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3490 - acc: 0.5306 - val_loss: 1.4396 - val_acc: 0.4938\n",
      "Epoch 225/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3480 - acc: 0.5300 - val_loss: 1.4279 - val_acc: 0.4958\n",
      "Epoch 226/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3464 - acc: 0.5299 - val_loss: 1.4242 - val_acc: 0.4968\n",
      "Epoch 227/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.3454 - acc: 0.5320 - val_loss: 1.4201 - val_acc: 0.4981\n",
      "Epoch 228/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3433 - acc: 0.5324 - val_loss: 1.4279 - val_acc: 0.4957\n",
      "Epoch 229/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3426 - acc: 0.5313 - val_loss: 1.4256 - val_acc: 0.4964\n",
      "Epoch 230/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.3413 - acc: 0.5315 - val_loss: 1.4322 - val_acc: 0.4942\n",
      "Epoch 231/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3396 - acc: 0.5321 - val_loss: 1.4215 - val_acc: 0.4971\n",
      "Epoch 232/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3379 - acc: 0.5327 - val_loss: 1.4184 - val_acc: 0.4985\n",
      "Epoch 233/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3366 - acc: 0.5337 - val_loss: 1.4202 - val_acc: 0.4986\n",
      "Epoch 234/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3349 - acc: 0.5332 - val_loss: 1.4267 - val_acc: 0.4953\n",
      "Epoch 235/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3342 - acc: 0.5337 - val_loss: 1.4183 - val_acc: 0.4993\n",
      "Epoch 236/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3323 - acc: 0.5368 - val_loss: 1.4148 - val_acc: 0.4992\n",
      "Epoch 237/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3312 - acc: 0.5361 - val_loss: 1.4167 - val_acc: 0.4996\n",
      "Epoch 238/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3304 - acc: 0.5364 - val_loss: 1.4195 - val_acc: 0.4936\n",
      "Epoch 239/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3287 - acc: 0.5366 - val_loss: 1.4174 - val_acc: 0.4964\n",
      "Epoch 240/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.3270 - acc: 0.5370 - val_loss: 1.4117 - val_acc: 0.5003\n",
      "Epoch 241/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.3264 - acc: 0.5375 - val_loss: 1.4202 - val_acc: 0.4946\n",
      "Epoch 242/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3247 - acc: 0.5386 - val_loss: 1.4173 - val_acc: 0.4975\n",
      "Epoch 243/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3238 - acc: 0.5386 - val_loss: 1.4247 - val_acc: 0.4983\n",
      "Epoch 244/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3220 - acc: 0.5389 - val_loss: 1.4088 - val_acc: 0.5027\n",
      "Epoch 245/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3214 - acc: 0.5392 - val_loss: 1.4194 - val_acc: 0.4988\n",
      "Epoch 246/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.3192 - acc: 0.5401 - val_loss: 1.4142 - val_acc: 0.4989\n",
      "Epoch 247/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3184 - acc: 0.5397 - val_loss: 1.4459 - val_acc: 0.4830\n",
      "Epoch 248/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3176 - acc: 0.5398 - val_loss: 1.4153 - val_acc: 0.4988\n",
      "Epoch 249/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3155 - acc: 0.5396 - val_loss: 1.4130 - val_acc: 0.5007\n",
      "Epoch 250/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.3143 - acc: 0.5416 - val_loss: 1.4087 - val_acc: 0.5032\n",
      "Epoch 251/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3130 - acc: 0.5416 - val_loss: 1.4069 - val_acc: 0.4989\n",
      "Epoch 252/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.3113 - acc: 0.5415 - val_loss: 1.4035 - val_acc: 0.5026\n",
      "Epoch 253/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3096 - acc: 0.5427 - val_loss: 1.4089 - val_acc: 0.5000\n",
      "Epoch 254/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.3089 - acc: 0.5433 - val_loss: 1.4213 - val_acc: 0.4969\n",
      "Epoch 255/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3078 - acc: 0.5432 - val_loss: 1.4066 - val_acc: 0.5015\n",
      "Epoch 256/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3063 - acc: 0.5444 - val_loss: 1.4103 - val_acc: 0.4988\n",
      "Epoch 257/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3056 - acc: 0.5442 - val_loss: 1.4016 - val_acc: 0.5052\n",
      "Epoch 258/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3042 - acc: 0.5459 - val_loss: 1.4067 - val_acc: 0.5012\n",
      "Epoch 259/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3030 - acc: 0.5448 - val_loss: 1.4196 - val_acc: 0.4959\n",
      "Epoch 260/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.3012 - acc: 0.5470 - val_loss: 1.4020 - val_acc: 0.5037\n",
      "Epoch 261/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.3001 - acc: 0.5454 - val_loss: 1.4031 - val_acc: 0.5032\n",
      "Epoch 262/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2991 - acc: 0.5458 - val_loss: 1.4047 - val_acc: 0.5049\n",
      "Epoch 263/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2974 - acc: 0.5478 - val_loss: 1.4129 - val_acc: 0.5010\n",
      "Epoch 264/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2958 - acc: 0.5480 - val_loss: 1.4126 - val_acc: 0.4996\n",
      "Epoch 265/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2946 - acc: 0.5474 - val_loss: 1.3984 - val_acc: 0.5061\n",
      "Epoch 266/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2941 - acc: 0.5480 - val_loss: 1.3958 - val_acc: 0.5067\n",
      "Epoch 267/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2915 - acc: 0.5498 - val_loss: 1.3989 - val_acc: 0.5040\n",
      "Epoch 268/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2914 - acc: 0.5485 - val_loss: 1.4060 - val_acc: 0.5021\n",
      "Epoch 269/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2896 - acc: 0.5501 - val_loss: 1.3964 - val_acc: 0.5052\n",
      "Epoch 270/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2886 - acc: 0.5506 - val_loss: 1.4029 - val_acc: 0.5022\n",
      "Epoch 271/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2881 - acc: 0.5496 - val_loss: 1.3971 - val_acc: 0.5068\n",
      "Epoch 272/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.2862 - acc: 0.5502 - val_loss: 1.4103 - val_acc: 0.4985\n",
      "Epoch 273/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2847 - acc: 0.5529 - val_loss: 1.3973 - val_acc: 0.5047\n",
      "Epoch 274/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2843 - acc: 0.5514 - val_loss: 1.3930 - val_acc: 0.5043\n",
      "Epoch 275/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.2826 - acc: 0.5518 - val_loss: 1.3943 - val_acc: 0.5029\n",
      "Epoch 276/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2816 - acc: 0.5535 - val_loss: 1.3916 - val_acc: 0.5069\n",
      "Epoch 277/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2792 - acc: 0.5543 - val_loss: 1.4124 - val_acc: 0.4985\n",
      "Epoch 278/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2785 - acc: 0.5550 - val_loss: 1.3894 - val_acc: 0.5052\n",
      "Epoch 279/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2774 - acc: 0.5541 - val_loss: 1.3997 - val_acc: 0.5038\n",
      "Epoch 280/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2763 - acc: 0.5556 - val_loss: 1.3894 - val_acc: 0.5097\n",
      "Epoch 281/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2756 - acc: 0.5537 - val_loss: 1.3908 - val_acc: 0.5040\n",
      "Epoch 282/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2740 - acc: 0.5562 - val_loss: 1.3859 - val_acc: 0.5098\n",
      "Epoch 283/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.2724 - acc: 0.5560 - val_loss: 1.3927 - val_acc: 0.5029\n",
      "Epoch 284/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2719 - acc: 0.5565 - val_loss: 1.3861 - val_acc: 0.5073\n",
      "Epoch 285/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.2703 - acc: 0.5573 - val_loss: 1.4227 - val_acc: 0.4972\n",
      "Epoch 286/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2690 - acc: 0.5581 - val_loss: 1.3882 - val_acc: 0.5079\n",
      "Epoch 287/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2680 - acc: 0.5576 - val_loss: 1.3938 - val_acc: 0.5069\n",
      "Epoch 288/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2671 - acc: 0.5584 - val_loss: 1.3818 - val_acc: 0.5124\n",
      "Epoch 289/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2656 - acc: 0.5575 - val_loss: 1.3890 - val_acc: 0.5056\n",
      "Epoch 290/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2649 - acc: 0.5599 - val_loss: 1.3972 - val_acc: 0.5019\n",
      "Epoch 291/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2632 - acc: 0.5595 - val_loss: 1.3832 - val_acc: 0.5096\n",
      "Epoch 292/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2622 - acc: 0.5593 - val_loss: 1.3973 - val_acc: 0.5022\n",
      "Epoch 293/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2611 - acc: 0.5610 - val_loss: 1.3889 - val_acc: 0.5045\n",
      "Epoch 294/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2596 - acc: 0.5615 - val_loss: 1.3912 - val_acc: 0.5084\n",
      "Epoch 295/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2582 - acc: 0.5611 - val_loss: 1.3866 - val_acc: 0.5066\n",
      "Epoch 296/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2571 - acc: 0.5613 - val_loss: 1.4079 - val_acc: 0.5035\n",
      "Epoch 297/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2563 - acc: 0.5614 - val_loss: 1.3783 - val_acc: 0.5139\n",
      "Epoch 298/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2553 - acc: 0.5613 - val_loss: 1.3787 - val_acc: 0.5128\n",
      "Epoch 299/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2542 - acc: 0.5617 - val_loss: 1.3809 - val_acc: 0.5105\n",
      "Epoch 300/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.2528 - acc: 0.5623 - val_loss: 1.3778 - val_acc: 0.5111\n",
      "Epoch 301/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2508 - acc: 0.5631 - val_loss: 1.3827 - val_acc: 0.5124\n",
      "Epoch 302/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2498 - acc: 0.5638 - val_loss: 1.3814 - val_acc: 0.5122\n",
      "Epoch 303/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.2493 - acc: 0.5646 - val_loss: 1.3908 - val_acc: 0.5083\n",
      "Epoch 304/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.2482 - acc: 0.5654 - val_loss: 1.3807 - val_acc: 0.5085\n",
      "Epoch 305/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2457 - acc: 0.5653 - val_loss: 1.3829 - val_acc: 0.5089\n",
      "Epoch 306/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2468 - acc: 0.5640 - val_loss: 1.3795 - val_acc: 0.5088\n",
      "Epoch 307/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2444 - acc: 0.5655 - val_loss: 1.3786 - val_acc: 0.5116\n",
      "Epoch 308/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2434 - acc: 0.5657 - val_loss: 1.3700 - val_acc: 0.5121\n",
      "Epoch 309/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2418 - acc: 0.5668 - val_loss: 1.3797 - val_acc: 0.5141\n",
      "Epoch 310/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2414 - acc: 0.5666 - val_loss: 1.3798 - val_acc: 0.5115\n",
      "Epoch 311/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.2399 - acc: 0.5679 - val_loss: 1.3836 - val_acc: 0.5088\n",
      "Epoch 312/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2386 - acc: 0.5677 - val_loss: 1.3760 - val_acc: 0.5125\n",
      "Epoch 313/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2368 - acc: 0.5682 - val_loss: 1.3874 - val_acc: 0.5075\n",
      "Epoch 314/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2357 - acc: 0.5685 - val_loss: 1.4256 - val_acc: 0.4981\n",
      "Epoch 315/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2353 - acc: 0.5703 - val_loss: 1.3853 - val_acc: 0.5073\n",
      "Epoch 316/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2340 - acc: 0.5699 - val_loss: 1.3719 - val_acc: 0.5120\n",
      "Epoch 317/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2328 - acc: 0.5709 - val_loss: 1.3734 - val_acc: 0.5103\n",
      "Epoch 318/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2323 - acc: 0.5695 - val_loss: 1.3697 - val_acc: 0.5129\n",
      "Epoch 319/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.2307 - acc: 0.5704 - val_loss: 1.3709 - val_acc: 0.5116\n",
      "Epoch 320/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2293 - acc: 0.5702 - val_loss: 1.3731 - val_acc: 0.5136\n",
      "Epoch 321/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.2284 - acc: 0.5707 - val_loss: 1.3759 - val_acc: 0.5121\n",
      "Epoch 322/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.2274 - acc: 0.5713 - val_loss: 1.3790 - val_acc: 0.5082\n",
      "Epoch 323/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2271 - acc: 0.5713 - val_loss: 1.3771 - val_acc: 0.5091\n",
      "Epoch 324/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2250 - acc: 0.5722 - val_loss: 1.3861 - val_acc: 0.5099\n",
      "Epoch 325/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.2245 - acc: 0.5728 - val_loss: 1.3653 - val_acc: 0.5141\n",
      "Epoch 326/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2225 - acc: 0.5733 - val_loss: 1.3786 - val_acc: 0.5146\n",
      "Epoch 327/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2219 - acc: 0.5732 - val_loss: 1.3760 - val_acc: 0.5098\n",
      "Epoch 328/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2207 - acc: 0.5738 - val_loss: 1.3675 - val_acc: 0.5162\n",
      "Epoch 329/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.2190 - acc: 0.5741 - val_loss: 1.3640 - val_acc: 0.5162\n",
      "Epoch 330/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2188 - acc: 0.5747 - val_loss: 1.3724 - val_acc: 0.5104\n",
      "Epoch 331/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2173 - acc: 0.5748 - val_loss: 1.3643 - val_acc: 0.5123\n",
      "Epoch 332/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2156 - acc: 0.5764 - val_loss: 1.3711 - val_acc: 0.5161\n",
      "Epoch 333/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2146 - acc: 0.5764 - val_loss: 1.3615 - val_acc: 0.5187\n",
      "Epoch 334/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2133 - acc: 0.5772 - val_loss: 1.3603 - val_acc: 0.5170\n",
      "Epoch 335/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.2129 - acc: 0.5766 - val_loss: 1.3673 - val_acc: 0.5159\n",
      "Epoch 336/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.2113 - acc: 0.5778 - val_loss: 1.3653 - val_acc: 0.5119\n",
      "Epoch 337/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2102 - acc: 0.5780 - val_loss: 1.3605 - val_acc: 0.5162\n",
      "Epoch 338/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2090 - acc: 0.5790 - val_loss: 1.3823 - val_acc: 0.5105\n",
      "Epoch 339/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2083 - acc: 0.5782 - val_loss: 1.3704 - val_acc: 0.5126\n",
      "Epoch 340/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2066 - acc: 0.5797 - val_loss: 1.3657 - val_acc: 0.5186\n",
      "Epoch 341/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.2061 - acc: 0.5793 - val_loss: 1.3660 - val_acc: 0.5128\n",
      "Epoch 342/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2047 - acc: 0.5803 - val_loss: 1.4252 - val_acc: 0.4977\n",
      "Epoch 343/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2041 - acc: 0.5790 - val_loss: 1.3652 - val_acc: 0.5138\n",
      "Epoch 344/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2022 - acc: 0.5804 - val_loss: 1.3616 - val_acc: 0.5180\n",
      "Epoch 345/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2019 - acc: 0.5804 - val_loss: 1.3680 - val_acc: 0.5136\n",
      "Epoch 346/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2005 - acc: 0.5801 - val_loss: 1.3548 - val_acc: 0.5181\n",
      "Epoch 347/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.2001 - acc: 0.5791 - val_loss: 1.3658 - val_acc: 0.5155\n",
      "Epoch 348/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1979 - acc: 0.5827 - val_loss: 1.3547 - val_acc: 0.5164\n",
      "Epoch 349/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1976 - acc: 0.5819 - val_loss: 1.3703 - val_acc: 0.5129\n",
      "Epoch 350/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1965 - acc: 0.5816 - val_loss: 1.3563 - val_acc: 0.5176\n",
      "Epoch 351/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1951 - acc: 0.5832 - val_loss: 1.3606 - val_acc: 0.5170\n",
      "Epoch 352/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1937 - acc: 0.5832 - val_loss: 1.3600 - val_acc: 0.5173\n",
      "Epoch 353/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1927 - acc: 0.5825 - val_loss: 1.3589 - val_acc: 0.5168\n",
      "Epoch 354/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1921 - acc: 0.5847 - val_loss: 1.3661 - val_acc: 0.5137\n",
      "Epoch 355/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1903 - acc: 0.5840 - val_loss: 1.3866 - val_acc: 0.5110\n",
      "Epoch 356/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1890 - acc: 0.5841 - val_loss: 1.3607 - val_acc: 0.5190\n",
      "Epoch 357/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1873 - acc: 0.5846 - val_loss: 1.3516 - val_acc: 0.5196\n",
      "Epoch 358/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1872 - acc: 0.5857 - val_loss: 1.3741 - val_acc: 0.5106\n",
      "Epoch 359/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1866 - acc: 0.5849 - val_loss: 1.3604 - val_acc: 0.5166\n",
      "Epoch 360/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1840 - acc: 0.5860 - val_loss: 1.3712 - val_acc: 0.5157\n",
      "Epoch 361/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1836 - acc: 0.5859 - val_loss: 1.3772 - val_acc: 0.5089\n",
      "Epoch 362/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1838 - acc: 0.5865 - val_loss: 1.3573 - val_acc: 0.5165\n",
      "Epoch 363/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1821 - acc: 0.5877 - val_loss: 1.3637 - val_acc: 0.5190\n",
      "Epoch 364/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1816 - acc: 0.5874 - val_loss: 1.3756 - val_acc: 0.5156\n",
      "Epoch 365/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1799 - acc: 0.5882 - val_loss: 1.3759 - val_acc: 0.5097\n",
      "Epoch 366/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.1790 - acc: 0.5881 - val_loss: 1.3516 - val_acc: 0.5212\n",
      "Epoch 367/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.1784 - acc: 0.5889 - val_loss: 1.3620 - val_acc: 0.5197\n",
      "Epoch 368/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.1768 - acc: 0.5886 - val_loss: 1.3607 - val_acc: 0.5186\n",
      "Epoch 369/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1751 - acc: 0.5898 - val_loss: 1.3647 - val_acc: 0.5130\n",
      "Epoch 370/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1745 - acc: 0.5894 - val_loss: 1.3531 - val_acc: 0.5183\n",
      "Epoch 371/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1731 - acc: 0.5906 - val_loss: 1.3534 - val_acc: 0.5209\n",
      "Epoch 372/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1720 - acc: 0.5914 - val_loss: 1.3589 - val_acc: 0.5178\n",
      "Epoch 373/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1708 - acc: 0.5909 - val_loss: 1.3874 - val_acc: 0.5092\n",
      "Epoch 374/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1701 - acc: 0.5907 - val_loss: 1.3820 - val_acc: 0.5077\n",
      "Epoch 375/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1693 - acc: 0.5920 - val_loss: 1.3583 - val_acc: 0.5177\n",
      "Epoch 376/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1681 - acc: 0.5925 - val_loss: 1.3588 - val_acc: 0.5154\n",
      "Epoch 377/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1668 - acc: 0.5933 - val_loss: 1.3520 - val_acc: 0.5224\n",
      "Epoch 378/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1662 - acc: 0.5924 - val_loss: 1.3511 - val_acc: 0.5228\n",
      "Epoch 379/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1648 - acc: 0.5937 - val_loss: 1.3574 - val_acc: 0.5186\n",
      "Epoch 380/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1636 - acc: 0.5946 - val_loss: 1.3487 - val_acc: 0.5200\n",
      "Epoch 381/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.1621 - acc: 0.5950 - val_loss: 1.3525 - val_acc: 0.5179\n",
      "Epoch 382/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1613 - acc: 0.5943 - val_loss: 1.3590 - val_acc: 0.5169\n",
      "Epoch 383/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1612 - acc: 0.5949 - val_loss: 1.3872 - val_acc: 0.5101\n",
      "Epoch 384/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1603 - acc: 0.5945 - val_loss: 1.3498 - val_acc: 0.5173\n",
      "Epoch 385/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.1587 - acc: 0.5961 - val_loss: 1.3538 - val_acc: 0.5190\n",
      "Epoch 386/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1576 - acc: 0.5957 - val_loss: 1.3770 - val_acc: 0.5162\n",
      "Epoch 387/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1563 - acc: 0.5965 - val_loss: 1.3427 - val_acc: 0.5209\n",
      "Epoch 388/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1547 - acc: 0.5974 - val_loss: 1.3770 - val_acc: 0.5128\n",
      "Epoch 389/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1540 - acc: 0.5977 - val_loss: 1.3534 - val_acc: 0.5220\n",
      "Epoch 390/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1544 - acc: 0.5966 - val_loss: 1.3646 - val_acc: 0.5139\n",
      "Epoch 391/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1515 - acc: 0.5966 - val_loss: 1.3462 - val_acc: 0.5210\n",
      "Epoch 392/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1521 - acc: 0.5975 - val_loss: 1.3543 - val_acc: 0.5212\n",
      "Epoch 393/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1502 - acc: 0.5969 - val_loss: 1.3398 - val_acc: 0.5240\n",
      "Epoch 394/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1499 - acc: 0.5974 - val_loss: 1.3446 - val_acc: 0.5221\n",
      "Epoch 395/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1465 - acc: 0.5992 - val_loss: 1.3401 - val_acc: 0.5255\n",
      "Epoch 396/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1465 - acc: 0.6000 - val_loss: 1.3513 - val_acc: 0.5220\n",
      "Epoch 397/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1456 - acc: 0.6008 - val_loss: 1.3420 - val_acc: 0.5260\n",
      "Epoch 398/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1441 - acc: 0.6011 - val_loss: 1.3909 - val_acc: 0.5112\n",
      "Epoch 399/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1437 - acc: 0.6011 - val_loss: 1.3774 - val_acc: 0.5152\n",
      "Epoch 400/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1428 - acc: 0.6009 - val_loss: 1.3468 - val_acc: 0.5202\n",
      "Epoch 401/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1416 - acc: 0.6020 - val_loss: 1.4047 - val_acc: 0.5056\n",
      "Epoch 402/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1407 - acc: 0.6006 - val_loss: 1.3604 - val_acc: 0.5169\n",
      "Epoch 403/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.1388 - acc: 0.6010 - val_loss: 1.3594 - val_acc: 0.5166\n",
      "Epoch 404/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1388 - acc: 0.6014 - val_loss: 1.3405 - val_acc: 0.5258\n",
      "Epoch 405/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1377 - acc: 0.6028 - val_loss: 1.3520 - val_acc: 0.5180\n",
      "Epoch 406/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.1359 - acc: 0.6032 - val_loss: 1.3449 - val_acc: 0.5210\n",
      "Epoch 407/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1351 - acc: 0.6030 - val_loss: 1.3523 - val_acc: 0.5193\n",
      "Epoch 408/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1341 - acc: 0.6039 - val_loss: 1.3509 - val_acc: 0.5237\n",
      "Epoch 409/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1332 - acc: 0.6043 - val_loss: 1.3477 - val_acc: 0.5223\n",
      "Epoch 410/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1320 - acc: 0.6055 - val_loss: 1.3440 - val_acc: 0.5248\n",
      "Epoch 411/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1302 - acc: 0.6053 - val_loss: 1.4246 - val_acc: 0.4968\n",
      "Epoch 412/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1300 - acc: 0.6058 - val_loss: 1.3464 - val_acc: 0.5248\n",
      "Epoch 413/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1291 - acc: 0.6068 - val_loss: 1.3559 - val_acc: 0.5187\n",
      "Epoch 414/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1291 - acc: 0.6064 - val_loss: 1.3523 - val_acc: 0.5194\n",
      "Epoch 415/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1273 - acc: 0.6062 - val_loss: 1.4079 - val_acc: 0.5047\n",
      "Epoch 416/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1257 - acc: 0.6073 - val_loss: 1.3526 - val_acc: 0.5165\n",
      "Epoch 417/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1260 - acc: 0.6074 - val_loss: 1.3573 - val_acc: 0.5183\n",
      "Epoch 418/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1235 - acc: 0.6086 - val_loss: 1.3573 - val_acc: 0.5195\n",
      "Epoch 419/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1232 - acc: 0.6084 - val_loss: 1.3829 - val_acc: 0.5103\n",
      "Epoch 420/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1207 - acc: 0.6081 - val_loss: 1.3598 - val_acc: 0.5181\n",
      "Epoch 421/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1205 - acc: 0.6081 - val_loss: 1.3691 - val_acc: 0.5138\n",
      "Epoch 422/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1199 - acc: 0.6087 - val_loss: 1.3552 - val_acc: 0.5207\n",
      "Epoch 423/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1187 - acc: 0.6085 - val_loss: 1.3451 - val_acc: 0.5235\n",
      "Epoch 424/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1183 - acc: 0.6102 - val_loss: 1.3562 - val_acc: 0.5209\n",
      "Epoch 425/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1162 - acc: 0.6122 - val_loss: 1.3335 - val_acc: 0.5255\n",
      "Epoch 426/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1162 - acc: 0.6097 - val_loss: 1.3435 - val_acc: 0.5258\n",
      "Epoch 427/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1148 - acc: 0.6105 - val_loss: 1.3425 - val_acc: 0.5265\n",
      "Epoch 428/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1137 - acc: 0.6106 - val_loss: 1.3738 - val_acc: 0.5145\n",
      "Epoch 429/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1138 - acc: 0.6090 - val_loss: 1.3516 - val_acc: 0.5181\n",
      "Epoch 430/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1114 - acc: 0.6127 - val_loss: 1.4055 - val_acc: 0.5083\n",
      "Epoch 431/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1102 - acc: 0.6108 - val_loss: 1.3478 - val_acc: 0.5211\n",
      "Epoch 432/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1103 - acc: 0.6127 - val_loss: 1.3720 - val_acc: 0.5178\n",
      "Epoch 433/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1097 - acc: 0.6117 - val_loss: 1.3597 - val_acc: 0.5207\n",
      "Epoch 434/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1076 - acc: 0.6120 - val_loss: 1.3341 - val_acc: 0.5265\n",
      "Epoch 435/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1080 - acc: 0.6122 - val_loss: 1.3559 - val_acc: 0.5186\n",
      "Epoch 436/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1054 - acc: 0.6139 - val_loss: 1.3322 - val_acc: 0.5289\n",
      "Epoch 437/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1030 - acc: 0.6151 - val_loss: 1.3678 - val_acc: 0.5133\n",
      "Epoch 438/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.1027 - acc: 0.6135 - val_loss: 1.3891 - val_acc: 0.5138\n",
      "Epoch 439/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.1019 - acc: 0.6151 - val_loss: 1.3704 - val_acc: 0.5171\n",
      "Epoch 440/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0994 - acc: 0.6154 - val_loss: 1.3396 - val_acc: 0.5220\n",
      "Epoch 441/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.1015 - acc: 0.6156 - val_loss: 1.3676 - val_acc: 0.5182\n",
      "Epoch 442/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0994 - acc: 0.6144 - val_loss: 1.3723 - val_acc: 0.5183\n",
      "Epoch 443/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0990 - acc: 0.6156 - val_loss: 1.3446 - val_acc: 0.5285\n",
      "Epoch 444/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0981 - acc: 0.6149 - val_loss: 1.3413 - val_acc: 0.5258\n",
      "Epoch 445/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0958 - acc: 0.6175 - val_loss: 1.4669 - val_acc: 0.4919\n",
      "Epoch 446/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0953 - acc: 0.6155 - val_loss: 1.3546 - val_acc: 0.5248\n",
      "Epoch 447/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0944 - acc: 0.6171 - val_loss: 1.3379 - val_acc: 0.5268\n",
      "Epoch 448/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0926 - acc: 0.6167 - val_loss: 1.3621 - val_acc: 0.5219\n",
      "Epoch 449/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0926 - acc: 0.6183 - val_loss: 1.3479 - val_acc: 0.5248\n",
      "Epoch 450/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0911 - acc: 0.6183 - val_loss: 1.3452 - val_acc: 0.5266\n",
      "Epoch 451/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0922 - acc: 0.6158 - val_loss: 1.3414 - val_acc: 0.5260\n",
      "Epoch 452/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0885 - acc: 0.6192 - val_loss: 1.3468 - val_acc: 0.5259\n",
      "Epoch 453/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0877 - acc: 0.6191 - val_loss: 1.3641 - val_acc: 0.5198\n",
      "Epoch 454/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0878 - acc: 0.6204 - val_loss: 1.3473 - val_acc: 0.5245\n",
      "Epoch 455/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0850 - acc: 0.6200 - val_loss: 1.3722 - val_acc: 0.5170\n",
      "Epoch 456/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0847 - acc: 0.6205 - val_loss: 1.3509 - val_acc: 0.5279\n",
      "Epoch 457/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0845 - acc: 0.6206 - val_loss: 1.4186 - val_acc: 0.5094\n",
      "Epoch 458/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0833 - acc: 0.6208 - val_loss: 1.3402 - val_acc: 0.5299\n",
      "Epoch 459/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0822 - acc: 0.6204 - val_loss: 1.3396 - val_acc: 0.5267\n",
      "Epoch 460/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0797 - acc: 0.6236 - val_loss: 1.3828 - val_acc: 0.5141\n",
      "Epoch 461/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0827 - acc: 0.6221 - val_loss: 1.3467 - val_acc: 0.5235\n",
      "Epoch 462/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0808 - acc: 0.6229 - val_loss: 1.3741 - val_acc: 0.5155\n",
      "Epoch 463/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0777 - acc: 0.6219 - val_loss: 1.3491 - val_acc: 0.5211\n",
      "Epoch 464/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0761 - acc: 0.6229 - val_loss: 1.3554 - val_acc: 0.5212\n",
      "Epoch 465/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0760 - acc: 0.6237 - val_loss: 1.3400 - val_acc: 0.5267\n",
      "Epoch 466/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0755 - acc: 0.6229 - val_loss: 1.3453 - val_acc: 0.5252\n",
      "Epoch 467/500\n",
      "50000/50000 [==============================] - 3s 53us/step - loss: 1.0725 - acc: 0.6255 - val_loss: 1.3426 - val_acc: 0.5262\n",
      "Epoch 468/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0737 - acc: 0.6238 - val_loss: 1.3386 - val_acc: 0.5311\n",
      "Epoch 469/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0759 - acc: 0.6241 - val_loss: 1.3978 - val_acc: 0.5096\n",
      "Epoch 470/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0716 - acc: 0.6258 - val_loss: 1.3359 - val_acc: 0.5275\n",
      "Epoch 471/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0703 - acc: 0.6272 - val_loss: 1.3852 - val_acc: 0.5125\n",
      "Epoch 472/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0692 - acc: 0.6266 - val_loss: 1.3811 - val_acc: 0.5179\n",
      "Epoch 473/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0670 - acc: 0.6261 - val_loss: 1.3806 - val_acc: 0.5194\n",
      "Epoch 474/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0683 - acc: 0.6265 - val_loss: 1.3710 - val_acc: 0.5222\n",
      "Epoch 475/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0643 - acc: 0.6267 - val_loss: 1.3645 - val_acc: 0.5179\n",
      "Epoch 476/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0656 - acc: 0.6276 - val_loss: 1.3988 - val_acc: 0.5082\n",
      "Epoch 477/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0653 - acc: 0.6285 - val_loss: 1.3331 - val_acc: 0.5271\n",
      "Epoch 478/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0638 - acc: 0.6279 - val_loss: 1.4195 - val_acc: 0.5064\n",
      "Epoch 479/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.0633 - acc: 0.6295 - val_loss: 1.3428 - val_acc: 0.5277\n",
      "Epoch 480/500\n",
      "50000/50000 [==============================] - 3s 57us/step - loss: 1.0583 - acc: 0.6307 - val_loss: 1.3359 - val_acc: 0.5288\n",
      "Epoch 481/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.0634 - acc: 0.6278 - val_loss: 1.3827 - val_acc: 0.5140\n",
      "Epoch 482/500\n",
      "50000/50000 [==============================] - 3s 58us/step - loss: 1.0586 - acc: 0.6294 - val_loss: 1.3267 - val_acc: 0.5302\n",
      "Epoch 483/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0590 - acc: 0.6298 - val_loss: 1.3311 - val_acc: 0.5290\n",
      "Epoch 484/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0581 - acc: 0.6308 - val_loss: 1.3387 - val_acc: 0.5268\n",
      "Epoch 485/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0560 - acc: 0.6316 - val_loss: 1.3492 - val_acc: 0.5237\n",
      "Epoch 486/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0551 - acc: 0.6310 - val_loss: 1.3387 - val_acc: 0.5319\n",
      "Epoch 487/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0554 - acc: 0.6308 - val_loss: 1.4093 - val_acc: 0.5086\n",
      "Epoch 488/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0553 - acc: 0.6316 - val_loss: 1.3813 - val_acc: 0.5176\n",
      "Epoch 489/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0532 - acc: 0.6313 - val_loss: 1.4027 - val_acc: 0.5104\n",
      "Epoch 490/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.0516 - acc: 0.6321 - val_loss: 1.3747 - val_acc: 0.5168\n",
      "Epoch 491/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.0490 - acc: 0.6330 - val_loss: 1.3293 - val_acc: 0.5305\n",
      "Epoch 492/500\n",
      "50000/50000 [==============================] - 3s 59us/step - loss: 1.0480 - acc: 0.6340 - val_loss: 1.3644 - val_acc: 0.5234\n",
      "Epoch 493/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.0491 - acc: 0.6348 - val_loss: 1.3382 - val_acc: 0.5285\n",
      "Epoch 494/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.0478 - acc: 0.6335 - val_loss: 1.3965 - val_acc: 0.5103\n",
      "Epoch 495/500\n",
      "50000/50000 [==============================] - 3s 56us/step - loss: 1.0498 - acc: 0.6343 - val_loss: 1.3959 - val_acc: 0.5162\n",
      "Epoch 496/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0461 - acc: 0.6341 - val_loss: 1.3619 - val_acc: 0.5228\n",
      "Epoch 497/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0472 - acc: 0.6343 - val_loss: 1.4137 - val_acc: 0.5095\n",
      "Epoch 498/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0434 - acc: 0.6342 - val_loss: 1.3793 - val_acc: 0.5175\n",
      "Epoch 499/500\n",
      "50000/50000 [==============================] - 3s 55us/step - loss: 1.0412 - acc: 0.6354 - val_loss: 1.3408 - val_acc: 0.5281\n",
      "Epoch 500/500\n",
      "50000/50000 [==============================] - 3s 54us/step - loss: 1.0426 - acc: 0.6346 - val_loss: 1.3451 - val_acc: 0.5280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f866bb41240>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "設定要訓練的 Epoch 數\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=500, \n",
    "          batch_size=256, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1885,
     "status": "ok",
     "timestamp": 1563810246735,
     "user": {
      "displayName": "林建宏",
      "photoUrl": "",
      "userId": "12416564836120847438"
     },
     "user_tz": -480
    },
    "id": "kbzohihxNX2u",
    "outputId": "508e2fe0-7f96-472e-d9c0-394bbdb0c9eb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 以視覺畫方式檢視訓練過程\n",
    "\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Day077_HW.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
