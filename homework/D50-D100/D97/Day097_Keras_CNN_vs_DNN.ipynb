{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"name":"Day097_Keras_CNN_vs_DNN.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"4k4ywQmV4FSe","colab_type":"code","colab":{}},"source":["import keras\n","from keras.datasets import cifar10\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.optimizers import RMSprop, Adam\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vJeU5lKF4LiW","colab_type":"code","colab":{}},"source":["# Disable GPU\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tLLZXBbh4FSi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"1a7c8703-5a07-45d3-fe61-f337a8d3355a","executionInfo":{"status":"ok","timestamp":1564811139169,"user_tz":-480,"elapsed":823,"user":{"displayName":"林建宏","photoUrl":"","userId":"12416564836120847438"}}},"source":["batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n","num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n","epochs = 20 # 訓練的 epochs 數量\n","\n","# 讀取資料並檢視\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VTLLALkS4FSk","colab_type":"text"},"source":["## 首先我們使用一般的 DNN (MLP) 來訓練\n","由於 DNN 只能輸入一維的資料，我們要先將影像進行攤平，若 (50000, 32, 32, 3) 的影像，攤平後會變成 (50000, 32*32*3) = (50000, 3072)"]},{"cell_type":"code","metadata":{"id":"jLIPd8fU4FSk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"f17f816f-a14b-4568-e541-7bbc483db070","executionInfo":{"status":"ok","timestamp":1564811143874,"user_tz":-480,"elapsed":1936,"user":{"displayName":"林建宏","photoUrl":"","userId":"12416564836120847438"}}},"source":["# 將資料攤平成一維資料\n","x_train = x_train.reshape(50000, 3072) \n","x_test = x_test.reshape(10000, 3072)\n","\n","# 將資料變為 float32 並標準化\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aEMxoIdU4FSm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"50474a68-0b9b-4d35-b7f1-7e2ea0849674","executionInfo":{"status":"ok","timestamp":1564811187954,"user_tz":-480,"elapsed":42404,"user":{"displayName":"林建宏","photoUrl":"","userId":"12416564836120847438"}}},"source":["model = Sequential()\n","model.add(Dense(512, activation='relu', input_shape=(3072,)))\n","model.add(Dropout(0.2))\n","model.add(Dense(512, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":22,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_11 (Dense)             (None, 512)               1573376   \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 512)               262656    \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 10)                5130      \n","=================================================================\n","Total params: 1,841,162\n","Trainable params: 1,841,162\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/20\n","50000/50000 [==============================] - 3s 55us/step - loss: 2.2348 - acc: 0.2475 - val_loss: 1.9119 - val_acc: 0.2993\n","Epoch 2/20\n","50000/50000 [==============================] - 2s 40us/step - loss: 1.8498 - acc: 0.3328 - val_loss: 1.7156 - val_acc: 0.3913\n","Epoch 3/20\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.7744 - acc: 0.3604 - val_loss: 1.6624 - val_acc: 0.4206\n","Epoch 4/20\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.7257 - acc: 0.3827 - val_loss: 1.6954 - val_acc: 0.3953\n","Epoch 5/20\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.6929 - acc: 0.3934 - val_loss: 1.6015 - val_acc: 0.4359\n","Epoch 6/20\n","50000/50000 [==============================] - 2s 40us/step - loss: 1.6592 - acc: 0.4041 - val_loss: 1.5802 - val_acc: 0.4352\n","Epoch 7/20\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.6430 - acc: 0.4137 - val_loss: 1.5915 - val_acc: 0.4273\n","Epoch 8/20\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.6251 - acc: 0.4237 - val_loss: 1.5578 - val_acc: 0.4540\n","Epoch 9/20\n","50000/50000 [==============================] - 2s 40us/step - loss: 1.6039 - acc: 0.4260 - val_loss: 1.5768 - val_acc: 0.4306\n","Epoch 10/20\n","50000/50000 [==============================] - 2s 40us/step - loss: 1.5891 - acc: 0.4360 - val_loss: 1.5534 - val_acc: 0.4462\n","Epoch 11/20\n","50000/50000 [==============================] - 2s 40us/step - loss: 1.5780 - acc: 0.4405 - val_loss: 1.5665 - val_acc: 0.4493\n","Epoch 12/20\n","50000/50000 [==============================] - 2s 40us/step - loss: 1.5663 - acc: 0.4428 - val_loss: 1.5120 - val_acc: 0.4719\n","Epoch 13/20\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.5580 - acc: 0.4454 - val_loss: 1.5517 - val_acc: 0.4588\n","Epoch 14/20\n","50000/50000 [==============================] - 2s 40us/step - loss: 1.5482 - acc: 0.4500 - val_loss: 1.6246 - val_acc: 0.4304\n","Epoch 15/20\n","50000/50000 [==============================] - 2s 40us/step - loss: 1.5423 - acc: 0.4495 - val_loss: 1.5137 - val_acc: 0.4683\n","Epoch 16/20\n","50000/50000 [==============================] - 2s 40us/step - loss: 1.5348 - acc: 0.4556 - val_loss: 1.5196 - val_acc: 0.4766\n","Epoch 17/20\n","50000/50000 [==============================] - 2s 40us/step - loss: 1.5195 - acc: 0.4552 - val_loss: 1.4807 - val_acc: 0.4761\n","Epoch 18/20\n","50000/50000 [==============================] - 2s 40us/step - loss: 1.5201 - acc: 0.4584 - val_loss: 1.5787 - val_acc: 0.4377\n","Epoch 19/20\n","50000/50000 [==============================] - 2s 40us/step - loss: 1.5111 - acc: 0.4621 - val_loss: 1.5377 - val_acc: 0.4508\n","Epoch 20/20\n","50000/50000 [==============================] - 2s 41us/step - loss: 1.5092 - acc: 0.4620 - val_loss: 1.5305 - val_acc: 0.4581\n","Test loss: 1.5304887666702272\n","Test accuracy: 0.4581\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LxicMnSN4FSo","colab_type":"text"},"source":["## 接下來我們使用 CNN 來訓練神經網路\n","CNN 的原理非常適合處理影像類的資料，就讓我們來看看，同樣的訓練條件，CNN 是否顯著優於 DNN 呢?"]},{"cell_type":"code","metadata":{"id":"iH5ROtZP4FSp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"15dfcde7-18d7-4a48-b612-4111b0c27eec","executionInfo":{"status":"ok","timestamp":1564810964353,"user_tz":-480,"elapsed":1119,"user":{"displayName":"林建宏","photoUrl":"","userId":"12416564836120847438"}}},"source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# Convert class vectors to binary class matrices.\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iTwC7Veu4FSq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1b2b9cf6-7a54-40d2-8b56-09a73f4273ec","executionInfo":{"status":"ok","timestamp":1564811080987,"user_tz":-480,"elapsed":114255,"user":{"displayName":"林建宏","photoUrl":"","userId":"12416564836120847438"}}},"source":["model = Sequential()\n","model.add(Conv2D(32, (3, 3), padding='same',\n","                 input_shape=x_train.shape[1:]))\n","model.add(Activation('relu'))\n","model.add(Conv2D(32, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same'))\n","model.add(Activation('relu'))\n","model.add(Conv2D(64, (3, 3)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes))\n","model.add(Activation('softmax'))\n","model.summary()\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer=RMSprop(),\n","              metrics=['accuracy'])\n","\n","history = model.fit(x_train, y_train,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    verbose=1,\n","                    validation_data=(x_test, y_test))\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 30, 30, 32)        9248      \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 30, 30, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 15, 15, 64)        18496     \n","_________________________________________________________________\n","activation_9 (Activation)    (None, 15, 15, 64)        0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 13, 13, 64)        36928     \n","_________________________________________________________________\n","activation_10 (Activation)   (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 512)               1180160   \n","_________________________________________________________________\n","activation_11 (Activation)   (None, 512)               0         \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 512)               0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 10)                5130      \n","_________________________________________________________________\n","activation_12 (Activation)   (None, 10)                0         \n","=================================================================\n","Total params: 1,250,858\n","Trainable params: 1,250,858\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/20\n","50000/50000 [==============================] - 6s 125us/step - loss: 1.7510 - acc: 0.3664 - val_loss: 1.3472 - val_acc: 0.5158\n","Epoch 2/20\n","50000/50000 [==============================] - 6s 112us/step - loss: 1.3223 - acc: 0.5297 - val_loss: 1.3491 - val_acc: 0.5192\n","Epoch 3/20\n","50000/50000 [==============================] - 6s 112us/step - loss: 1.1159 - acc: 0.6080 - val_loss: 0.9693 - val_acc: 0.6596\n","Epoch 4/20\n","50000/50000 [==============================] - 6s 111us/step - loss: 0.9864 - acc: 0.6573 - val_loss: 0.9379 - val_acc: 0.6760\n","Epoch 5/20\n","50000/50000 [==============================] - 6s 112us/step - loss: 0.8986 - acc: 0.6872 - val_loss: 0.8789 - val_acc: 0.6925\n","Epoch 6/20\n","50000/50000 [==============================] - 6s 112us/step - loss: 0.8333 - acc: 0.7095 - val_loss: 0.8035 - val_acc: 0.7208\n","Epoch 7/20\n","50000/50000 [==============================] - 6s 113us/step - loss: 0.7763 - acc: 0.7299 - val_loss: 0.7585 - val_acc: 0.7384\n","Epoch 8/20\n","50000/50000 [==============================] - 6s 112us/step - loss: 0.7358 - acc: 0.7452 - val_loss: 0.7313 - val_acc: 0.7495\n","Epoch 9/20\n","50000/50000 [==============================] - 6s 111us/step - loss: 0.7003 - acc: 0.7589 - val_loss: 0.6706 - val_acc: 0.7695\n","Epoch 10/20\n","50000/50000 [==============================] - 6s 111us/step - loss: 0.6713 - acc: 0.7681 - val_loss: 0.7338 - val_acc: 0.7606\n","Epoch 11/20\n","50000/50000 [==============================] - 6s 112us/step - loss: 0.6460 - acc: 0.7780 - val_loss: 0.7130 - val_acc: 0.7616\n","Epoch 12/20\n","50000/50000 [==============================] - 6s 113us/step - loss: 0.6308 - acc: 0.7842 - val_loss: 0.7061 - val_acc: 0.7696\n","Epoch 13/20\n","50000/50000 [==============================] - 6s 111us/step - loss: 0.6198 - acc: 0.7869 - val_loss: 0.6518 - val_acc: 0.7830\n","Epoch 14/20\n","50000/50000 [==============================] - 6s 111us/step - loss: 0.6043 - acc: 0.7934 - val_loss: 0.7146 - val_acc: 0.7750\n","Epoch 15/20\n","50000/50000 [==============================] - 6s 111us/step - loss: 0.5986 - acc: 0.7961 - val_loss: 0.7973 - val_acc: 0.7508\n","Epoch 16/20\n","50000/50000 [==============================] - 6s 111us/step - loss: 0.5995 - acc: 0.7971 - val_loss: 0.6796 - val_acc: 0.7793\n","Epoch 17/20\n","50000/50000 [==============================] - 6s 110us/step - loss: 0.5911 - acc: 0.8013 - val_loss: 0.6896 - val_acc: 0.7838\n","Epoch 18/20\n","50000/50000 [==============================] - 6s 110us/step - loss: 0.5892 - acc: 0.8037 - val_loss: 0.6909 - val_acc: 0.7951\n","Epoch 19/20\n","50000/50000 [==============================] - 6s 110us/step - loss: 0.5925 - acc: 0.8020 - val_loss: 0.6722 - val_acc: 0.7903\n","Epoch 20/20\n","50000/50000 [==============================] - 6s 110us/step - loss: 0.5929 - acc: 0.8032 - val_loss: 0.6461 - val_acc: 0.7911\n","Test loss: 0.6460621257305146\n","Test accuracy: 0.7911\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FMhx_Njo4FSs","colab_type":"text"},"source":["## 同樣運算 10 個 epochs，但 CNN 在 test data 的準確率顯著優於 DNN!"]},{"cell_type":"markdown","metadata":{"id":"EF6evwTI4FSt","colab_type":"text"},"source":["## 作業\n","1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響?\n","2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪?\n","\n","ANS:\n","1. epochs數量\n","2. DNN參數數量較多，因為全連接會使參數膨脹"]}]}